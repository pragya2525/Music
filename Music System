pip install streamlit




from pyngrok import conf, installer
installer.install_ngrok(conf.get_default().ngrok_path)




from pyngrok import ngrok
ngrok.set_auth_token("31KPNKThRlF8Ve4fhErGw15OBhn_6Dp2eZfKvqx94zp1tTRjZ")




!pip install -q pandas numpy matplotlib seaborn scikit-learn streamlit pyngrok




from IPython.display import Markdown, display
display(Markdown("# SelfMade Music Recommendation System\n"
                 "Project 2: Spotify Songs‚Äô Genre Segmentation\n"
                 "Pre-processing ‚Ä¢ EDA ‚Ä¢ Correlation ‚Ä¢ Clustering ‚Ä¢ Recommendation ‚Ä¢ Web App (global via ngrok)"))




import os, pandas as pd
CSV_FILE = "spotify_dataset.csv"
assert os.path.exists(CSV_FILE), f"Place '{CSV_FILE}' in this folder."
df = pd.read_csv(CSV_FILE)
print("Shape:", df.shape)
df.head()




import numpy as np
df.drop_duplicates(inplace=True)
text_cols = [
    "track_id","track_name","track_artist","track_album_name",
    "playlist_name","playlist_genre","playlist_subgenre"
]
for c in text_cols:
    if c in df.columns:
        df[c] = df[c].astype(str)
    else:
        print(f"‚ö†Ô∏è Missing text column: {c}")
num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
for c in num_cols:
    df[c].fillna(df[c].median(), inplace=True)
for c in text_cols:
    if c in df.columns:
        df[c].replace(["", "nan", "None", "NaN"], np.nan, inplace=True)
        df[c].fillna("Unknown", inplace=True)
print("After preprocessing:", df.shape)
df[text_cols].head()




# Genre distribution
if "playlist_genre" in df.columns:
    topg = df["playlist_genre"].value_counts().head(12)
    plt.figure(figsize=(9,5))
    sns.barplot(x=topg.values, y=topg.index)
    plt.title("Top Playlist Genres")
    plt.xlabel("Count"); plt.ylabel("playlist_genre"); plt.tight_layout(); plt.show()

# Subgenre distribution 
if "playlist_subgenre" in df.columns:
    topsg = df["playlist_subgenre"].value_counts().head(12)
    plt.figure(figsize=(9,5))
    sns.barplot(x=topsg.values, y=topsg.index)
    plt.title("Top Playlist Subgenres")
    plt.xlabel("Count"); plt.ylabel("playlist_subgenre"); plt.tight_layout(); plt.show()

# Popularity distribution
if "track_popularity" in df.columns:
    plt.figure(figsize=(8,4))
    sns.histplot(df["track_popularity"], bins=30, kde=True)
    plt.title("Track Popularity Distribution")
    plt.xlabel("track_popularity"); plt.tight_layout(); plt.show()




corr_cols = [
    "danceability","energy","key","loudness","mode","speechiness",
    "acousticness","instrumentalness","liveness","valence",
    "tempo","duration_ms","track_popularity"
]
avail = [c for c in corr_cols if c in df.columns]
print("Correlation features:", avail)
plt.figure(figsize=(12,8))
sns.heatmap(df[avail].corr(), cmap="coolwarm", square=True)
plt.title("Correlation Matrix"); plt.tight_layout(); plt.show()




from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA

model_feats = [
    "danceability","energy","loudness","speechiness","acousticness",
    "instrumentalness","liveness","valence","tempo",
    "duration_ms","track_popularity"
]
features = [f for f in model_feats if f in df.columns]
print("Clustering features:", features)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(df[features].fillna(df[features].median()))
kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)
df["Cluster"] = kmeans.fit_predict(X_scaled)
pca = PCA(n_components=2, random_state=42)
p2 = pca.fit_transform(X_scaled)
df["PCA1"], df["PCA2"] = p2[:,0], p2[:,1]
df["Cluster"].value_counts().sort_index()




plt.figure(figsize=(8,6))
sns.scatterplot(data=df, x="PCA1", y="PCA2", hue="Cluster", palette="tab10", s=18)
plt.title("Song Clusters (PCA)"); plt.legend(title="Cluster"); plt.tight_layout(); plt.show()




# Top genres per cluster
if "playlist_genre" in df.columns:
    top_g = (
        df.groupby(["Cluster","playlist_genre"])
          .size().reset_index(name="count")
          .sort_values(["Cluster","count"], ascending=[True, False])
          .groupby("Cluster").head(3)
    )
    print("Top playlist_genre per cluster:")
    display(top_g)

# Top playlists per cluster
if "playlist_name" in df.columns:
    top_p = (
        df.groupby(["Cluster","playlist_name"])
          .size().reset_index(name="count")
          .sort_values(["Cluster","count"], ascending=[True, False])
          .groupby("Cluster").head(3)
    )
    print("Top playlist_name per cluster:")
    display(top_p)


CLEAN = "spotify_cleaned.csv"
df.to_csv(CLEAN, index=False)
print("Saved:", CLEAN)





%%writefile spotify_app.py
import streamlit as st
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import NearestNeighbors
import urllib.parse

df = pd.read_csv("spotify_cleaned.csv")

st.set_page_config(page_title="SelfMade Music Recommendation System", layout="wide")
st.markdown("""
<style>
/* Page background: bluish gradient */
[data-testid="stAppViewContainer"] {
  background: linear-gradient(135deg, #a7d3ff 0%, #1e3c72 100%);
}
.block-container {max-width: 1100px;}
/* white search input */
.stTextInput > div > div > input {
  background: #ffffff !important; color: #000 !important;
  border-radius: 10px; border: 1px solid #ddd;
}
/* golden buttons */
.stButton > button {
  background: linear-gradient(90deg, #d4af37, #f1c40f);
  color: #000; font-weight: 700; border-radius: 10px; border: 0;
  padding: 0.5rem 1rem;
}
/* result card */
.song-card {
  background: rgba(255,255,255,0.08);
  border: 1px solid rgba(255,255,255,0.18);
  border-radius: 12px; padding: 12px 14px; margin-bottom: 10px; color: #fff;
}
a { color: #ffe082; font-weight: 600; text-decoration: none; }
a:hover { text-decoration: underline; }
</style>
""", unsafe_allow_html=True)

st.title("üéµ SelfMade Music Recommendation System")
st.caption("Project 2: Spotify Songs‚Äô Genre Segmentation ‚Äî Search ¬∑ Correlate ¬∑ Cluster ¬∑ Recommend")

search_field = st.selectbox(
    "Search by",
    ["Any","track_id","track_name","track_artist","track_album_name","playlist_name","playlist_genre","playlist_subgenre"]
)
query = st.text_input("Enter your search term (case-insensitive):", "")

def search_rows(q: str, field: str) -> pd.DataFrame:
    if not q: return pd.DataFrame()
    ql = q.lower()
    if field == "Any":
        mask = pd.Series(False, index=df.index)
        for c in ["track_id","track_name","track_artist","track_album_name","playlist_name","playlist_genre","playlist_subgenre"]:
            if c in df.columns:
                mask |= df[c].astype(str).str.lower().str.contains(ql, na=False)
        return df[mask]
    else:
        if field in df.columns:
            return df[df[field].astype(str).str.lower().str.contains(ql, na=False)]
        return pd.DataFrame()
 
feat_cols = [c for c in [
    "danceability","energy","loudness","speechiness","acousticness",
    "instrumentalness","liveness","valence","tempo","duration_ms","track_popularity"
] if c in df.columns]
nn = None; X = None
if len(feat_cols) >= 2:
    scaler = StandardScaler()
    X = scaler.fit_transform(df[feat_cols].fillna(df[feat_cols].median()).values)
    nn = NearestNeighbors(n_neighbors=11, metric="euclidean")
    nn.fit(X)

if st.button("Search"):
    res = search_rows(query, search_field)
    if res.empty:
        st.error(f"Not Found ‚Äî no matches for '{query}' in '{search_field}'.")
    else:
        show = res.head(200)
        for idx, row in show.iterrows():
        
            st.markdown(f"""
            <div class="song-card">
              <div><b>{row.get('track_name','')}</b> ‚Äî {row.get('track_artist','')}</div>
              <div>Album: {row.get('track_album_name','')}</div>
              <div>Playlist: {row.get('playlist_name','')} | Genre: {row.get('playlist_genre','')} | Subgenre: {row.get('playlist_subgenre','')}</div>
            </div>
            """, unsafe_allow_html=True)

            yt_q = urllib.parse.quote_plus(f"{row.get('track_name','')} {row.get('track_artist','')}")
            yt_link = f"https://www.youtube.com/results?search_query={yt_q}"
            st.markdown(f"üîó **YouTube (Play/Search first):** [{row.get('track_name','')} on YouTube]({yt_link})")

            tid = str(row.get("track_id","")).strip()
            if tid and tid.lower() != "unknown":
                sp_link = f"https://open.spotify.com/track/{tid}"
            else:
                sp_q = urllib.parse.quote_plus(f"{row.get('track_name','')} {row.get('track_artist','')}")
                sp_link = f"https://open.spotify.com/search/{sp_q}"
            st.markdown(f"üéß **Spotify (second):** [{row.get('track_name','')} on Spotify]({sp_link})")
 
            if nn is not None and X is not None:
                try:
                    distances, indices = nn.kneighbors(X[idx:idx+1], n_neighbors=11)
                    neighbors = indices.flatten().tolist()
                    if neighbors and neighbors[0] == idx:
                        neighbors = neighbors[1:11]
                    else:
                        neighbors = neighbors[:10]
                    recs = df.iloc[neighbors]
                    with st.expander("Show 10 similar songs"):
                        for _, r in recs.iterrows():
                            st.write(f"- {r.get('track_name','')} ‚Äî {r.get('track_artist','')} ({r.get('playlist_genre','')})")
                except Exception:
                    pass
st.markdown("---")
st.caption("YouTube link appears first; Spotify second. Use 'Any' to search across all fields.")




!pip install pyngrok streamlit -q

import os
import subprocess
import time
from pyngrok import ngrok

NGROK_TOKEN = "31KPNKThRlF8Ve4fhErGw15OBhn_6Dp2eZfKvqx94zp1tTRjZ"  # apna token paste karo
os.environ["NGROK_AUTHTOKEN"] = NGROK_TOKEN
ngrok.set_auth_token(NGROK_TOKEN)

try:
    subprocess.run(["fuser", "-k", "8501/tcp"])
except:
    pass

subprocess.Popen(["streamlit", "run", "spotify_app.py", "--server.port", "8501", "--server.headless", "true"])

public_url = ngrok.connect(8501)
print("üåç Public URL:", public_url)



! jupyter nbconvert --to script "Pragya Kumari.ipynb"
